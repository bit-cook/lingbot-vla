model:
  model_path: /path/to/LingBot-VLA-Depth
  tokenizer_path: /path/to/Qwen2.5-VL-3B-Instruct/
  post_training: true
  adanorm_time: true
  old_adanorm: true
  moge_path: /path/to/moge2-vitb-normal
  morgbd_path: /path/to/LingBot-Depth-Pretrained

data:
  datasets_type: vla
  data_name: robotwin_5_new
  train_path: /path/to/mixed_robotwin_5tasks
  num_workers: 8
  norm_type: bounds_99_woclip
  norm_stats_file: assets/norm_stats/robotwin_50.json

train:
  output_dir: /path/to/lingbot_depth_robotwin5tasks/
  loss_type: L1_fm
  data_parallel_mode: fsdp2
  enable_full_shard: false
  module_fsdp_enable: true
  use_compile: true
  use_wandb: false
  rmpad: false
  rmpad_with_pos_ids: false
  ulysses_parallel_size: 1
  freeze_vision_encoder: false
  tokenizer_max_length: 24
  action_dim: 14
  max_action_dim: 75
  max_state_dim: 75
  lr: 1.0e-4
  lr_decay_style: constant
  num_train_epochs: 69
  micro_batch_size: 32
  global_batch_size: 256
  max_steps: 220000
  ckpt_manager: dcp
  save_steps: 220000
  save_epochs: 69
  enable_fp32: true
  enable_resume: true
  align_params:
    mode: 'query'
    num_task_tokens: 8
    use_image_tokens: True
    use_task_tokens: False
    use_text_tokens: False
    use_contrastive: True
    contrastive_loss_weight: 0.3
    depth_loss_weight: 0.002
    llm:
      dim_out: 2048
      image_token_size: 8
      image_input_size: 224
    depth:
      model_type: MoRGBD
      num_layers: 1
      num_heads: 4
      dim_head: 32
      ff_mult: 1
      num_backbone_tokens: 256
      token_size: 16
      dim_out: 1024
      input_size: 224
    visual_steps: 10000